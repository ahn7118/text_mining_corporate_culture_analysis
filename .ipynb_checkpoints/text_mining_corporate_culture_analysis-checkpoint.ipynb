{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('C:\\\\Users\\\\an-user\\\\Downloads\\\\chromedriver.exe')\n",
    "browser.implicitly_wait(5)\n",
    "browser.get('https://www.jobplanet.co.kr/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Raw Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##list for raw data\n",
    "title_list = []\n",
    "advantage_list = []\n",
    "drawback_list = []\n",
    "opinion_list = []\n",
    "personal_info = []\n",
    "promotion, welfareandsalary, worklifebalance, corporateculture, executives = [], [],[],[],[]\n",
    "\n",
    "##crawling data from Jobplanet\n",
    "for board_number in range(1, 25):\n",
    "    browser.get(\"https://www.jobplanet.co.kr/companies/60632/reviews/%EC%9C%84%EB%A9%94%ED%94%84?page=&page=\" + str(board_number))\n",
    "    contents = browser.find_elements_by_css_selector('div.content_wrap')\n",
    "    clean_contents = contents[:2] + contents[4:]\n",
    "\n",
    "    for i in range(len(clean_contents)):\n",
    "        ##personal_info and text info\n",
    "        text = clean_contents[i].text.split('\\n')\n",
    "        personal_info.append(text[:text.index('평점')])\n",
    "        title_list.append(' '.join(str(text[12:text.index('장점')])))\n",
    "        advantage_list.append(' '.join(str(text[text.index('장점') + 1 : text.index('단점')])))\n",
    "        drawback_list.append(' '.join(str(text[text.index('단점') + 1 : text.index('경영진에 바라는 점')])))\n",
    "        opinion_list.append(' '.join(str(text[text.index('경영진에 바라는 점') + 1 : -5])))\n",
    "    \n",
    "        ##score info\n",
    "        html = clean_contents[i].get_attribute('outerHTML')\n",
    "        attributes = str(BeautifulSoup(html, 'lxml')).split('\\n')\n",
    "        promotion.append(re.findall(r'\\d+', attributes[21]))\n",
    "        welfareandsalary.append(re.findall(r'\\d+', attributes[27]))\n",
    "        worklifebalance.append(re.findall(r'\\d+', attributes[33]))\n",
    "        corporateculture.append(re.findall(r'\\d+', attributes[39]))\n",
    "        executives.append(re.findall(r'\\d+', attributes[45]))\n",
    "\n",
    "        \n",
    "##Converting list into dataframe\n",
    "personal_info_df = pd.DataFrame(personal_info, columns = ['info'])\n",
    "title_df = pd.DataFrame(title_list, columns = ['title'])\n",
    "advantage_df = pd.DataFrame(advantage_list, columns = ['advantage'])\n",
    "drawback_df = pd.DataFrame(drawback_list, columns = ['drawback'])\n",
    "opinion_df = pd.DataFrame(opinion_list, columns = ['opinion'])\n",
    "promotion_score = pd.DataFrame(promotion, columns = ['promotion'])\n",
    "welfareandsalary_score = pd.DataFrame(welfareandsalary, columns = ['welfaresalary'])\n",
    "worklifebalance_score = pd.DataFrame(worklifebalance, columns = ['worklifebalance'])\n",
    "corporateculture_score = pd.DataFrame(corporateculture, columns = ['culture'])\n",
    "executives_score = pd.DataFrame(executives, columns = ['executives'])\n",
    "\n",
    "## Merging Data\n",
    "df = pd.concat([personal_info_df,\n",
    "                     title_df,\n",
    "                     advantage_df,\n",
    "                     drawback_df,\n",
    "                     opinion_df,\n",
    "                     promotion_score,\n",
    "                     welfareandsalary_score,\n",
    "                     worklifebalance_score,\n",
    "                     corporateculture_score,\n",
    "                     executives_score], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 10 columns):\n",
      "info               120 non-null object\n",
      "title              120 non-null object\n",
      "advantage          120 non-null object\n",
      "drawback           120 non-null object\n",
      "opinion            120 non-null object\n",
      "promotion          120 non-null object\n",
      "welfaresalary      120 non-null object\n",
      "worklifebalance    120 non-null object\n",
      "culture            120 non-null object\n",
      "executives         120 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total'] = \"\"\n",
    "df['date'] = ''\n",
    "df['region'] = ''\n",
    "df['workingstatus'] = ''\n",
    "df['department'] = ''\n",
    "for i in range(len(df)):\n",
    "    ##converting 0 to 100 score scale into 1 to 5 score scale. \n",
    "    df['promotion'][i] = int(df['promotion'][i])/20\n",
    "    df['welfaresalary'][i] = int(df['welfaresalary'][i])/20\n",
    "    df['worklifebalance'][i] = int(df['worklifebalance'][i])/20\n",
    "    df['culture'][i] = int(df['culture'][i])/20\n",
    "    df['executives'][i] = int(df['executives'][i])/20\n",
    "    df['total'][i] = (df['executives'][i] + df['culture'][i] + df['worklifebalance'][i] + df['welfaresalary'][i] + df['promotion'][i])/5\n",
    "    \n",
    "    \n",
    "    ##spliting personal information of each observation\n",
    "    information = df['info'][i].split('|')\n",
    "    df['date'][i] = pd.to_datetime(information[3])\n",
    "    df['region'][i] = information[2]\n",
    "    df['workingstatus'][i] = information[1]\n",
    "    df['department'][i] = information[0]\n",
    "    \n",
    "    ##removing characters from string of each text information\n",
    "    df['title'][i] = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', df['title'][i])\n",
    "    df['advantage'][i] = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', df['advantage'][i])\n",
    "    df['drawback'][i] = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', df['drawback'][i])\n",
    "    df['opinion'][i] = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', df['opinion'][i])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>title</th>\n",
       "      <th>advantage</th>\n",
       "      <th>drawback</th>\n",
       "      <th>opinion</th>\n",
       "      <th>promotion</th>\n",
       "      <th>welfaresalary</th>\n",
       "      <th>worklifebalance</th>\n",
       "      <th>culture</th>\n",
       "      <th>executives</th>\n",
       "      <th>total</th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>workingstatus</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>IT/인터넷 | 현직원 | 서울 | 2019/4/21</td>\n",
       "      <td>복지도 잘 되어있고 같이 일하는 분위기가 자유로움</td>\n",
       "      <td>연차 자유롭고 분위기 자유로움 복지도 잘 되어 있음 지하철역과 가까움</td>\n",
       "      <td>영업손실이 나서 불안함 투자가 많아짐 업계 2워 자리 내어줌</td>\n",
       "      <td>연봉 많이 올려주세요 연봉 많이 올려주세요</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-21 00:00:00</td>\n",
       "      <td>서울</td>\n",
       "      <td>현직원</td>\n",
       "      <td>IT/인터넷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>IT/인터넷 | 현직원 | 서울 | 2019/4/3</td>\n",
       "      <td>경력 쌓고 싶으면 오세요 열려있습니다</td>\n",
       "      <td>경력 쌓기는 괜찮고 존중하는 업무분위기 연차 자유 지하철역 근처</td>\n",
       "      <td>오래다니기엔 비전이 없고 동종 업계에서 하락하는 추세 10년 후에 내 자리가 없을지도</td>\n",
       "      <td>회사에 신경 좀 써주세요</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2019-04-03 00:00:00</td>\n",
       "      <td>서울</td>\n",
       "      <td>현직원</td>\n",
       "      <td>IT/인터넷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>영업/제휴 | 전직원 | 서울 | 2019/4/26</td>\n",
       "      <td>분위기 매우 좋고 승진 기회가 많은 회사</td>\n",
       "      <td>젊은 사람들 위주라 분위기가 매우 화기애애하고 재밌고 자유로움</td>\n",
       "      <td>부서마다 분위기가 매우 다르고 가끔 빡세게 야근하는 경우가 발생 경영의 줏대가 없는 느낌</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2019-04-26 00:00:00</td>\n",
       "      <td>서울</td>\n",
       "      <td>전직원</td>\n",
       "      <td>영업/제휴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>마케팅/시장조사 | 전직원 | 서울 | 2019/7/15</td>\n",
       "      <td>시대에 맞춰 복지를 다양하게 개선하려고 하지만 아직 옛 사고방식을 버리지 못한 기업</td>\n",
       "      <td>팀마다 분위기가 매우 다름 구내식당 아침1000원 점심2500원 저녁1000원 퀄리...</td>\n",
       "      <td>쓸데없는 일을 만들어서 사서 고생하는 스타일 다른 직원들에게 올 파장은 생각 안하고...</td>\n",
       "      <td>작은 계획의 변경이 모든 직원들에게 올 큰 파장과 리스크를 생각했으면 한다</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2019-07-15 00:00:00</td>\n",
       "      <td>서울</td>\n",
       "      <td>전직원</td>\n",
       "      <td>마케팅/시장조사</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                info  \\\n",
       "95     IT/인터넷 | 현직원 | 서울 | 2019/4/21   \n",
       "111     IT/인터넷 | 현직원 | 서울 | 2019/4/3   \n",
       "91      영업/제휴 | 전직원 | 서울 | 2019/4/26   \n",
       "30   마케팅/시장조사 | 전직원 | 서울 | 2019/7/15   \n",
       "\n",
       "                                              title  \\\n",
       "95                      복지도 잘 되어있고 같이 일하는 분위기가 자유로움   \n",
       "111                            경력 쌓고 싶으면 오세요 열려있습니다   \n",
       "91                           분위기 매우 좋고 승진 기회가 많은 회사   \n",
       "30   시대에 맞춰 복지를 다양하게 개선하려고 하지만 아직 옛 사고방식을 버리지 못한 기업   \n",
       "\n",
       "                                             advantage  \\\n",
       "95              연차 자유롭고 분위기 자유로움 복지도 잘 되어 있음 지하철역과 가까움   \n",
       "111                경력 쌓기는 괜찮고 존중하는 업무분위기 연차 자유 지하철역 근처   \n",
       "91                  젊은 사람들 위주라 분위기가 매우 화기애애하고 재밌고 자유로움   \n",
       "30   팀마다 분위기가 매우 다름 구내식당 아침1000원 점심2500원 저녁1000원 퀄리...   \n",
       "\n",
       "                                              drawback  \\\n",
       "95                   영업손실이 나서 불안함 투자가 많아짐 업계 2워 자리 내어줌   \n",
       "111    오래다니기엔 비전이 없고 동종 업계에서 하락하는 추세 10년 후에 내 자리가 없을지도   \n",
       "91   부서마다 분위기가 매우 다르고 가끔 빡세게 야근하는 경우가 발생 경영의 줏대가 없는 느낌   \n",
       "30   쓸데없는 일을 만들어서 사서 고생하는 스타일 다른 직원들에게 올 파장은 생각 안하고...   \n",
       "\n",
       "                                       opinion promotion welfaresalary  \\\n",
       "95                     연봉 많이 올려주세요 연봉 많이 올려주세요         3             3   \n",
       "111                              회사에 신경 좀 써주세요         3             4   \n",
       "91                                                     4             2   \n",
       "30   작은 계획의 변경이 모든 직원들에게 올 큰 파장과 리스크를 생각했으면 한다         4             4   \n",
       "\n",
       "    worklifebalance culture executives total                 date region  \\\n",
       "95                3       3          3     3  2019-04-21 00:00:00    서울    \n",
       "111               3       4          2   3.2  2019-04-03 00:00:00    서울    \n",
       "91                4       4          3   3.4  2019-04-26 00:00:00    서울    \n",
       "30                4       2          2   3.2  2019-07-15 00:00:00    서울    \n",
       "\n",
       "    workingstatus department  \n",
       "95           현직원     IT/인터넷   \n",
       "111          현직원     IT/인터넷   \n",
       "91           전직원      영업/제휴   \n",
       "30           전직원   마케팅/시장조사   "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wemakeprice.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorizing datasets into categories\n",
    "\n",
    "(1) High Job Satisfaction Group - Hyundai, SK Telecome, Naver\n",
    "\n",
    "(2) Low Job Satisfaction Group - Eland, WeMakePrice, Samsung Automobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf1 = pd.read_csv('hyundai_df.csv')\n",
    "hdf1 = hdf1.fillna('NaN')\n",
    "\n",
    "\n",
    "hdf2 = pd.read_csv('naver_df.csv')\n",
    "hdf2 = hdf2.fillna('NaN')\n",
    "\n",
    "\n",
    "hdf3 = pd.read_csv('skt_df.csv')\n",
    "hdf3 = hdf3.fillna('NaN')\n",
    "\n",
    "\n",
    "ldf1 = pd.read_csv('elandworld.csv')\n",
    "ldf1 = ldf1.fillna('NaN')\n",
    "\n",
    "\n",
    "\n",
    "ldf2 = pd.read_csv('renaultsamsung_df.csv')\n",
    "ldf2 = ldf2.fillna('NaN')\n",
    "\n",
    "\n",
    "ldf3 = pd.read_csv('wemakeprice.csv')\n",
    "ldf3 = ldf3.fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf1['company'] = '현대자동차'\n",
    "hdf2['company'] = '네이버'\n",
    "hdf3['company'] = 'sk텔레콤'\n",
    "\n",
    "ldf1['company'] = '이랜드'\n",
    "ldf2['company'] = '르노삼성'\n",
    "ldf3['company'] = '위메프'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_df = pd.concat([hdf1, hdf2, hdf3], axis = 0)\n",
    "high_df.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "low_df = pd.concat([ldf1, ldf2, ldf3], axis = 0)\n",
    "low_df.drop(['Unnamed: 0'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resetting row numbers for clean dataframe.\n",
    "high_df = high_df.reset_index(drop=True)\n",
    "low_df = low_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294 entries, 0 to 293\n",
      "Data columns (total 16 columns):\n",
      "info               294 non-null object\n",
      "title              294 non-null object\n",
      "advantage          294 non-null object\n",
      "drawback           294 non-null object\n",
      "opinion            294 non-null object\n",
      "promotion          294 non-null float64\n",
      "welfaresalary      294 non-null float64\n",
      "worklifebalance    294 non-null float64\n",
      "culture            294 non-null float64\n",
      "executives         294 non-null float64\n",
      "total              294 non-null float64\n",
      "date               294 non-null object\n",
      "region             294 non-null object\n",
      "workingstatus      294 non-null object\n",
      "department         294 non-null object\n",
      "company            294 non-null object\n",
      "dtypes: float64(6), object(10)\n",
      "memory usage: 36.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 264 entries, 0 to 263\n",
      "Data columns (total 16 columns):\n",
      "info               264 non-null object\n",
      "title              264 non-null object\n",
      "advantage          264 non-null object\n",
      "drawback           264 non-null object\n",
      "opinion            264 non-null object\n",
      "promotion          264 non-null float64\n",
      "welfaresalary      264 non-null float64\n",
      "worklifebalance    264 non-null float64\n",
      "culture            264 non-null float64\n",
      "executives         264 non-null float64\n",
      "total              264 non-null float64\n",
      "date               264 non-null object\n",
      "region             264 non-null object\n",
      "workingstatus      264 non-null object\n",
      "department         264 non-null object\n",
      "company            264 non-null object\n",
      "dtypes: float64(6), object(10)\n",
      "memory usage: 33.1+ KB\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(high_df.info(),\n",
    "    low_df.info(), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Text File for Frequency Analysis for Each Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_df['total_text'] = high_df['title'] + ' ' + high_df['advantage'] + ' '+high_df['drawback'] + ' '+high_df['opinion']\n",
    "low_df['total_text'] = low_df['title'] + ' ' + low_df['advantage'] + ' '+ low_df['drawback'] + ' '+ low_df['opinion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Saving Dataframe as Text File\n",
    "f = open(\"high_total_text.txt\", 'w')\n",
    "for i in range(high_df.shape[0]):\n",
    "    data = high_df.total_text[i]\n",
    "    f.write(data)\n",
    "f.close()\n",
    "\n",
    "g = open(\"low_total_text.txt\", 'w')\n",
    "for i in range(low_df.shape[0]):\n",
    "    data = low_df.total_text[i]\n",
    "    g.write(data)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##packages for frequency analysis\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Twitter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Uploading stop words list file\n",
    "stop_words = open('stop_words.txt', 'r').read()\n",
    "stop_words = stop_words.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋은 98\n",
      "많이 90\n",
      "회사 88\n",
      "복지 58\n",
      "많음 56\n",
      "너무 55\n",
      "많은 47\n",
      "좀 44\n",
      "대한 41\n",
      "업무 39\n"
     ]
    }
   ],
   "source": [
    "##tokenizing words and country frequency \n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "high_text_file = open('high_total_text.txt', 'r').read()\n",
    "word_tokens = word_tokenize(high_text_file)\n",
    "\n",
    "high_result = []\n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        high_result.append(w) \n",
    "\n",
    "\n",
    "for w, c in Counter(high_result).most_common(10):\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회사 127\n",
      "너무 73\n",
      "없음 71\n",
      "많이 57\n",
      "많음 56\n",
      "좋은 52\n",
      "연차 48\n",
      "분위기 44\n",
      "좋음 40\n",
      "일을 39\n"
     ]
    }
   ],
   "source": [
    "##tokenizing words and country frequency \n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "low_text_file = open('low_total_text.txt', 'r').read()\n",
    "word_tokens = word_tokenize(low_text_file)\n",
    "\n",
    "low_result = []\n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        low_result.append(w) \n",
    "\n",
    "\n",
    "for w, c in Counter(low_result).most_common(10):\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\an-user\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\an-user\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회사 232\n",
      "복지 166\n",
      "일 143\n",
      "업무 134\n",
      "기업 133\n",
      "문화 116\n",
      "사람 116\n",
      "분위기 108\n",
      "직 101\n",
      "연봉 99\n"
     ]
    }
   ],
   "source": [
    "##counting words by  morpheme\n",
    "##Counting Frequent Nouns for High Group\n",
    "\n",
    "twitter = Twitter()\n",
    "high_nouns = twitter.nouns(high_text_file)\n",
    "high_noun_result = []\n",
    "for w in high_nouns: \n",
    "    if w not in stop_words: \n",
    "        high_noun_result.append(w) \n",
    "\n",
    "\n",
    "for w, c in Counter(high_noun_result).most_common(10):\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회사 274\n",
      "사람 178\n",
      "일 167\n",
      "업무 127\n",
      "직원 111\n",
      "연봉 99\n",
      "복지 99\n",
      "함 95\n",
      "분위기 94\n",
      "연차 84\n"
     ]
    }
   ],
   "source": [
    "##counting words by  morpheme\n",
    "##Counting Frequent Nouns for Low Group\n",
    "low_nouns = twitter.nouns(low_text_file)\n",
    "low_noun_result = []\n",
    "for w in low_nouns: \n",
    "    if w not in stop_words: \n",
    "        low_noun_result.append(w) \n",
    "\n",
    "\n",
    "for w, c in Counter(low_noun_result).most_common(10):\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('하는', 'Verb') 139\n",
      "('좋은', 'Adjective') 131\n",
      "('많음', 'Adjective') 59\n",
      "('많은', 'Adjective') 52\n",
      "('높은', 'Adjective') 48\n",
      "('없음', 'Adjective') 47\n",
      "('좋음', 'Adjective') 38\n",
      "('있고', 'Adjective') 33\n",
      "('자유로운', 'Adjective') 31\n",
      "('하면', 'Verb') 30\n"
     ]
    }
   ],
   "source": [
    "##Counting Verbs or Adjectives \n",
    "##Counts for High Group\n",
    "\n",
    "high_pos = twitter.pos(high_text_file)\n",
    "\n",
    "high_verb_adj = []\n",
    "\n",
    "for i in range(len(high_pos)):\n",
    "    if high_pos[i][1] == 'Verb' or high_pos[i][1] == 'Adjective':\n",
    "        high_verb_adj.append(high_pos[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "high_result = []\n",
    "for w in high_verb_adj: \n",
    "    if w[0] not in stop_words:\n",
    "        high_result.append(w)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "for w, c in Counter(high_result).most_common(10):\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('하는', 'Verb') 139\n",
      "('좋은', 'Adjective') 131\n",
      "('많음', 'Adjective') 59\n",
      "('많은', 'Adjective') 52\n",
      "('높은', 'Adjective') 48\n",
      "('없음', 'Adjective') 47\n",
      "('좋음', 'Adjective') 38\n",
      "('있고', 'Adjective') 33\n",
      "('자유로운', 'Adjective') 31\n",
      "('하면', 'Verb') 30\n"
     ]
    }
   ],
   "source": [
    "low_pos = twitter.pos(high_text_file)\n",
    "\n",
    "low_verb_adj = []\n",
    "\n",
    "for i in range(len(low_pos)):\n",
    "    if low_pos[i][1] == 'Verb' or low_pos[i][1] == 'Adjective':\n",
    "        low_verb_adj.append(low_pos[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "low_result = []\n",
    "for w in low_verb_adj: \n",
    "    if w[0] not in stop_words:\n",
    "        low_result.append(w)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "for w, c in Counter(low_result).most_common(10):\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis plan\n",
    "\n",
    "Purpose: Converting Text Data to Keyword Format\n",
    "\n",
    "1. By reading each observation, each text data is going to be converted into keywords\n",
    "- keywords are going to be arranged by each column. For example, advantage keyword and drawback keyword are going to be seperated.\n",
    " \n",
    "2. Frequency Analysis for Keyword \n",
    "\n",
    "3. Categorizing Keywords based on Attractiveness/Avoidance Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting high group's text into keyword data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_keyword_df = high_df[['title', 'advantage', 'drawback', 'opinion', 'total_text', 'company']]\n",
    "high_keyword_df['title_key'] = ''\n",
    "high_keyword_df['advantage_key'] = ''\n",
    "high_keyword_df['drawback_key'] = ''\n",
    "high_keyword_df['opinion_key'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_keyword_df = pd.read_csv('high_keyword_df.csv')\n",
    "high_keyword_df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294 entries, 0 to 293\n",
      "Data columns (total 10 columns):\n",
      "title            294 non-null object\n",
      "advantage        294 non-null object\n",
      "drawback         294 non-null object\n",
      "opinion          262 non-null object\n",
      "total_text       294 non-null object\n",
      "company          294 non-null object\n",
      "title_key        294 non-null object\n",
      "advantage_key    294 non-null object\n",
      "drawback_key     294 non-null object\n",
      "opinion_key      294 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 23.0+ KB\n"
     ]
    }
   ],
   "source": [
    "high_keyword_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting low group's text into keyword data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\an-user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\an-user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\an-user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\an-user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "low_keyword_df = low_df[['title', 'advantage', 'drawback', 'opinion', 'total', 'company']]\n",
    "low_keyword_df['title_key'] = ''\n",
    "low_keyword_df['advantage_key'] = ''\n",
    "low_keyword_df['drawback_key'] = ''\n",
    "low_keyword_df['opinion_key'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_keyword_df = pd.read_csv('low_keyword_df.csv')\n",
    "low_keyword_df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 264 entries, 0 to 263\n",
      "Data columns (total 10 columns):\n",
      "title            264 non-null object\n",
      "advantage        264 non-null object\n",
      "drawback         264 non-null object\n",
      "opinion          179 non-null object\n",
      "total            264 non-null float64\n",
      "company          264 non-null object\n",
      "title_key        264 non-null object\n",
      "advantage_key    264 non-null object\n",
      "drawback_key     264 non-null object\n",
      "opinion_key      264 non-null object\n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 20.7+ KB\n"
     ]
    }
   ],
   "source": [
    "low_keyword_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
